---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

This is Zhiyang Qi (æ–‰ å¿—æš). Iâ€™m currently a PhD student at The University of Electro-Communications under the supervision of <a href='https://www.inaba.aix.uec.ac.jp/'>Assoc. Prof. Michimasa Inaba</a>. My research direction is about dialogue systems. My recent work is about how to adapt dialogue systems to different users.

I am also interested in the following content:
- Psychological Counseling Dialogue
- Dialogue System about Board Games
- Dialogue System Competition

Warmly welcome any academic cooperation and discussion!!


# ğŸ”¥ News
- *2024.06*: &nbsp;ğŸ“‘ I have completed a position paper for <a href='https://sites.google.com/view/yrrsds2024/home?authuser=0'>YRRSDS2024</a>, which will be held at Kyoto University on September 16-17.


# ğŸ“– Educations
- *2023.04 - Now*, Ph.D. candidate in Informatics, The University of Electro-Communications.
- *2021.04 - 2023.03*, M.S. in Informatics, The University of Electro-Communications.
- *2015.09 - 2019.06*, B.S. in Software Engineering, Qingdao University of Science & Technology.


# ğŸ¤– Competition Experience
- *2024.05* <a href='https://sites.google.com/view/aiwolfdial2024jp/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0?authuser=0'>äººç‹¼çŸ¥èƒ½ã‚³ãƒ³ãƒ†ã‚¹ãƒˆ2024å›½å†…å¤§ä¼šè‡ªç„¶è¨€èªéƒ¨é–€</a>ï¼ˆTeam: **UEC-IL**, **2nd** out of 5 teamsï¼‰
- *2023.12* <a href='https://sites.google.com/view/dialogrobotcompe3/home?authuser=0'>å¯¾è©±ãƒ­ãƒœãƒƒãƒˆã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³2023ï¼ˆDRC2023ï¼‰</a>ï¼ˆTeam: **UEC-IL**, **6th** out of 12 teamsï¼‰
- *2023.12* <a href='https://sites.google.com/view/dslc6/%E3%83%9B%E3%83%BC%E3%83%A0?authuser=0'>å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ãƒ©ã‚¤ãƒ–ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³6</a>ï¼ˆTeam: **UECIL**, **3rd** out of 9 teamsï¼‰
- *2023.09* <a href='https://sigdialinlg2023.github.io/paper_inlg136.html'>Natural Language Division of 5th International AIWolf Contestï¼ˆAIWolfDial 2023ï¼‰</a>in <a href='https://sigdialinlg2023.github.io/index.html'>INLG 2023</a>ï¼ˆTeam: **sUper_IL**, **1st** out of 9 teamsï¼‰


# ğŸ– Honors and Awards

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

